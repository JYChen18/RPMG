<!DOCTYPE HTML>
<html>
	<head>
		<title> RPMG </title>
		<meta charset="utf-8" />
		<!-- <meta name="viewport" content="width=device-width, initial-scale=1.0" /> -->
        <meta name="viewport" content="width=1000">
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
          ga('create', 'UA-89797207-1', 'auto');
          ga('send', 'pageview');
        </script>

      <meta property="og:url"           content="https://jychen18.github.io/RPMG" />
	    <meta property="og:type"          content="website" />
	    <meta property="og:title"         content="Projective Manifold Gradient Layer for Deep Rotation Regression" />
	    <meta property="og:description"   content="Regressing rotations on SO(3) manifold using deep neural networks is an important yet unsolved problem. The gap between the Euclidean network output space and the non-Euclidean SO(3) manifold imposes a severe challenge for neural network learning in both forward and backward passes. While several works have proposed different regression-friendly rotation representations, very few works have been devoted to improving the gradient backpropagating in the backward pass. In this paper, we propose a manifold-aware gradient that directly backpropagates into deep network weights. Leveraging Riemannian optimization to construct a novel projective gradient, our proposed regularized projective manifold gradient (RPMG) method helps networks achieve new state-of-the-art performance in a variety of rotation estimation tasks. Our proposed gradient layer can also be applied to other smooth manifolds such as the unit sphere. Our project page is at https://jychen18.github.io/RPMG." />
        <meta property="og:image" content="images/illustration.png" />
	</head>
	<body id="top">

		<!-- Main -->
			<div id="main" style="padding-bottom:1em; padding-top: 5em; width: 60em; max-width: 70em; margin-left: auto; margin-right: auto;">
					<section id="four">
						
						<h2 style="text-align: center; margin-bottom: 5px;"><font color="4e79a7"></font>Projective Manifold Gradient Layer for Deep Rotation Regression</h2>
						<h3 style="text-align: center; margin-bottom: 5px;"><font color="4ea9a7">CVPR 2022</font></h3>
                        <h4 style="text-align: center; margin-bottom: 5px;">
                            <a href="https://jychen18.github.io/">Jiayi Chen</a><sup>1, 2</sup>&nbsp; &nbsp; 
                            <a href="https://yd-yin.github.io/">Yingda Yin</a><sup>1</sup>&nbsp; &nbsp; 
                            <a href="https://tolgabirdal.github.io/">Tolga Birdal</a><sup>3, 4</sup>&nbsp; &nbsp; 
                            <a href="https://cfcs.pku.edu.cn/baoquan">Baoquan Chen</a><sup>1</sup>&nbsp; &nbsp;
                            <a href="https://geometry.stanford.edu/member/guibas/index.html">Leonidas J. Guibas</a><sup>3</sup>&nbsp; &nbsp; 
                            <a href="https://hughw19.github.io/">He Wang</a><sup>1†</sup></h4>
                        
                             <p style="text-align: center;"><span style="font-size: 16px;">
                                <sup>1</sup>CFCS, Peking University&nbsp; &nbsp; 
                                <sup>2</sup>Beijing Institute for General AI&nbsp; &nbsp; 
                                <sup>3</sup>Stanford University&nbsp; &nbsp;
                                <sup>4</sup>Imperial College London
                            </p>
                            <!-- <p style="text-align: left;"> †: corresponding author -->
                            <section>
                                <div class="box alt" style="margin-bottom: 2em;" >
                                    <div class="row 50% uniform" style="width: 80%; margin-left: 35%">
                                        <div class="2u" style="font-size: 1.0em; text-align: center;">
                                        <a href="https://arxiv.org/abs/2110.11657" style="border-bottom: none;">
                                        <span style="margin-bottom: 0.5em;">
                                        <img src="images/icons/paper.png" height="75px"/>
                                        </span>
                                        Paper</a>
                                        </div>
                                        <div class="2u" style="font-size: 1.0em; text-align: center;">
                                        <a href="https://github.com/jychen18/RPMG" style="border-bottom: none;">
                                        <span style="margin-bottom: 0.5em;">
                                        <img src="images/icons/code.png" height="75px"/>
                                        </span>
                                        Code</a>
                                        </div>
                                </div>
                            </section>
    
                        <hr style="margin-top: 2em;">

						<h3>Abstract</h3>
						<p style="text-align:left; margin-top: -10px"> &nbsp;&nbsp;&nbsp;&nbsp;Regressing rotations on SO(3) 
                            manifold using deep neural networks is an important yet unsolved problem. The gap between the 
                            Euclidean network output space and the non-Euclidean SO(3) manifold imposes a severe challenge 
                            for neural network learning in both forward and backward passes. While several works have proposed 
                            different regression-friendly rotation representations, very few works have been devoted to 
                            improving the gradient backpropagating in the backward pass. In this paper, we propose a 
                            manifold-aware gradient that directly backpropagates into deep network weights. Leveraging 
                            Riemannian optimization to construct a novel projective gradient, our proposed regularized 
                            projective manifold gradient (RPMG) method helps networks achieve new state-of-the-art 
                            performance in a variety of rotation estimation tasks. Our proposed gradient layer can also 
                            be applied to other smooth manifolds such as the unit sphere. </p>

						
						<hr style="margin-top: 2em;">
						<h3>Method Overview</h3>
						<span class="center"><img src="images/method.png" width="75%"><img src="images/illustration.png" width="25%"></span>
						<p style="text-align:left; width: 100%; margin-left: 0%">
						<b>Figure 1</b>: <b style="font-weight: bold;">Regularized Projective Manifold Gradient Layer.</b> Left: full pipeline. Right: Illustration. In the forward pass, the network predicts a raw output x, which is then transformed into
                        a valid rotation R = ϕ(π(x)). We leave this forward pass unchanged and only modify the backward pass. In the backward pass, we first
                        use <b style="font-weight: bold;">Riemannian optimization</b> to get a goal rotation R<sub>g</sub> and map it back to ˆx<sub>g</sub> on the representation manifold M. After that we <b style="font-weight: bold;">find the
                        element x<sub>gp</sub> </b> which is closest to the raw output in the inverse image of ˆx<sub>g</sub>, and finally get the gradient g<sub>RPM</sub> we want.</p> 
						
						<hr style="margin-top: 2em;">
						<h3>Results</h3>
                        <span class="center"><img src="images/PC_number.png" width="70%"><img src="images/PC_Training_curve_airplane.png" width="30%"></span>
						<p style="text-align:left; width: 100%; margin-left: 0%">
                        <b>Table 1:</b> <b style="font-weight: bold;">3D object pose estimation from ModelNet40 point clouds.</b> Left: a comparison of methods by mean, median, and 5<sup>◦</sup> accuracy of (geodesic)
                        errors after 30k training steps. Mn, Md and Acc are abbreviations of mean, median and 5<sup>◦</sup> accuracy. Right: median test error of <i>airplane</i>
                        in different iterations during training. </p>
						
                        
                        <span class="center"><img src="images/Img_number.png" width="65%"><img src="images/ModelNetimg_training_curve_chair.png" width="35%"></span>
						<p style="text-align:left; width: 100%; margin-left: 0%">
						<b>Table 2:</b> <b style="font-weight: bold;">3D object pose estimation from ModelNet10 images.</b> Left: a comparison of methods by mean, median, and 5<sup>◦</sup> accuracy of (geodesic)
                        errors after 600k training steps. Mn, Md and Acc are abbreviations of mean, median and 5<sup>◦</sup> accuracy. Right: median test error of <i>chair</i>
                        in different iterations during training. </p>
						
						<p style="text-align: center; margin-bottom: -3px;"><img src="images/selfsup_number.png" width="35%"></p>
						<p style="text-align:left; width: 100%; margin-left: 0%">
						<b>Table 3:</b> <b style="font-weight: bold;">Self-supervised instance-level 3D object pose estimation
                        from ModelNet40 chair by chamfer distance loss.</b> We report mean, median, and 3<sup>◦</sup> accuracy of (geodesic)
                        errors after 30k training steps. <css style="text-decoration: underline">9D-inf fails when our methods still perform very well.</css> </p>

                        <p style="text-align: center; margin-bottom: -3px;"><img src="images/Camera_number.png" width="65%"></p>
						<p style="text-align:left; width: 100%; margin-left: 0%">
						<b>Table 4:</b> <b style="font-weight: bold;">Camera relocalization on Cambridge Landscape dataset.</b> We report the median error of translation and rotation of the best
                        checkpoint, which is chosen by minimizing the median error of rotation. We only care about the rotation error here, since we don't tune the loss weights for a fair comparison.</p>
						
                        <p style="text-align: center; margin-bottom: -3px;"><img src="images/sphere_number.png" width="35%"></p>
						<p style="text-align:left; width: 100%; margin-left: 0%">
						<b>Table 5:</b> <b style="font-weight: bold;">Unit vector regression from ModelNet40 bottle point clouds.</b> We report mean, median, and 1<sup>◦</sup> accuracy of (geodesic)
                        errors after 30k training steps. We can find that <css style="text-decoration: underline">our method can work well on other manifolds, <i>e.g.</i> S</css><sup>2</sup>. </p>


						<hr style="margin-top: 2em;">

						<div class="row" style="margin-top: 1em">
							<div class="12u$ 1u$(xsmall)">
								<h3>Bibtex</h3>
								<pre style="text-align:left;"><code>@article{chen2021projective,
    title={Projective Manifold Gradient Layer for Deep Rotation Regression},
    author={Chen, Jiayi and Yin, Yingda and Birdal, Tolga and Chen, Baoquan and Guibas, Leonidas and Wang, He},
    journal={arXiv preprint arXiv:2110.11657},
    year={2021}
}</code></pre>
							</div>
						</div>

                        <hr/ style="margin-top: 1em">
				        <h3>Contact</h3>
				        <p>If you have any questions, please feel free to contact <a href="https://jychen18.github.io/">Jiayi Chen</a> or <a href="https://hughw19.github.io/">He Wang</a>.  </p>
						<hr/>

					</section>
			</div>

			<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
	</body>
</html>